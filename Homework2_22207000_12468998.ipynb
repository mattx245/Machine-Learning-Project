{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd18450f",
   "metadata": {},
   "source": [
    "## Housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, classification_report, mean_squared_error\n",
    "import math\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3905fbf7",
   "metadata": {},
   "source": [
    "## Preamble - Data Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c39551bf",
   "metadata": {},
   "source": [
    "To clean our data, we have reused some of the code we had employed earlier on in the course. We first concatenate these files in the below cell block, and run this file through our scrubber which is where we handle our data cleaning. For further details, you can review the scrubber notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7165f338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining the two datasets and saving as a new csv\n",
    "df1 = pd.read_csv('covid19-cdc-22207000.csv', keep_default_na=True, delimiter=',', skipinitialspace=True)\n",
    "df2 = pd.read_csv('covid19-cdc-12468998.csv', keep_default_na=True, delimiter=',', skipinitialspace=True)\n",
    "\n",
    "combined_df = pd.concat([df1, df2])\n",
    "\n",
    "combined_df.to_csv('covid19-cdc-combined-22207000-12468998.csv', index=False)\n",
    "\n",
    "print(len(combined_df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06add5d1",
   "metadata": {},
   "source": [
    "The product of this scrubber is <b>finalised-covid19-cdc-combined-22207000-12468998.csv</b>. We will create our train/test dataframes from this csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2ced43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the post-scrubbed CSV and checking length\n",
    "df = pd.read_csv('finalised-covid19-cdc-combined-22207000-12468998.csv', keep_default_na=True, delimiter=',', skipinitialspace=True)\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98991013",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3217a8f4",
   "metadata": {},
   "source": [
    "# 1.1 Train/Test Split\n",
    "\n",
    "With the data cleaning taken care of, we can now conduct a train text split on the data to prepare it for future machine learning tasks. Once the data is split, we can plot the train frame and investigate the relationships between the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4340f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data for task 1\n",
    "df = pd.read_csv('finalised-covid19-cdc-combined-22207000-12468998.csv', keep_default_na=True, delimiter=',', skipinitialspace=True)\n",
    "\n",
    "#train test split on data\n",
    "train, test = train_test_split(df, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3cff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e524462",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a73bb470",
   "metadata": {},
   "source": [
    "# 1.2 Mapping our Training Set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a586122",
   "metadata": {},
   "source": [
    "## Correlation Between Continuous Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a21b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(20, 6), ncols=1, nrows=1)\n",
    "plt.scatter(train['case_positive_specimen_interval'], train['case_onset_interval'])\n",
    "corr = train['case_onset_interval'].corr(train['case_positive_specimen_interval'])\n",
    "print('Correlation: ', corr)\n",
    "print('Weak positive correlation between these two variables.')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70f635a1",
   "metadata": {},
   "source": [
    "## Continuous Features Plotted Against Death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c16460",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(20, 6), ncols=1, nrows=1)\n",
    "plt.scatter(train['death_yn'], train['case_positive_specimen_interval'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f9da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(20, 6), ncols=1, nrows=1)\n",
    "plt.scatter(train['death_yn'], train['case_onset_interval'])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3b894ca",
   "metadata": {},
   "source": [
    "## Health Related Categorical Features Plotted Against Death\n",
    "\n",
    "Here we are looking discern patterns from our dataset by plotting deaths (yes/no) against a select number of categorical features. The features we are going to examine first are those that relate to the health profile of our patients:\n",
    "\n",
    "1. When the patient contracted COVID.\n",
    "2. What US state the patient was in when they were reported of having COVID.\n",
    "3. What age group the patient belongs to.\n",
    "4. Whether the patient knew if they were exposed to COVID.\n",
    "5. Whether or not the patient was hospitalised or not.\n",
    "6. Whether or not the patient was taken to ICU.\n",
    "7. And whether or not the patient exhibited underlying conditions which could exacerbate COVID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1fed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = train['death_yn']\n",
    "select_features = [train['case_month'], train['res_state'], train['age_group'], train['hosp_yn'], train['exposure_yn'], train['icu_yn'], train['underlying_conditions_yn']]\n",
    "\n",
    "for feature in select_features:\n",
    "  \n",
    "    fig, axs = plt.subplots(ncols=2, figsize=(20, 8))\n",
    "    train.groupby([feature, target_feature]).size().unstack().plot(kind='bar', stacked=True, ax=axs[0])\n",
    "    axs[0].set_xticklabels(axs[0].get_xticklabels(), rotation=90, fontsize=10)\n",
    "    axs[0].set_ylabel('%')\n",
    "\n",
    "    train.groupby([feature, target_feature]).size().unstack().apply(lambda x: x/x.sum(), axis=1).plot(kind='bar', stacked=True, ax=axs[1])\n",
    "    axs[1].set_xticklabels(axs[1].get_xticklabels(), rotation=90, fontsize=10)\n",
    "    axs[1].set_ylabel('#')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216ea269",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = train['underlying_conditions_yn']\n",
    "select_features = [train['hosp_yn'], train['icu_yn'], train['death_yn']]\n",
    "\n",
    "for feature in select_features:\n",
    "  \n",
    "    fig, axs = plt.subplots(ncols=2, figsize=(20, 8))\n",
    "    train.groupby([feature, target_feature]).size().unstack().plot(kind='bar', stacked=True, ax=axs[0])\n",
    "    axs[0].set_xticklabels(axs[0].get_xticklabels(), rotation=90, fontsize=10)\n",
    "    axs[0].set_ylabel('%')\n",
    "\n",
    "    train.groupby([feature, target_feature]).size().unstack().apply(lambda x: x/x.sum(), axis=1).plot(kind='bar', stacked=True, ax=axs[1])\n",
    "    axs[1].set_xticklabels(axs[1].get_xticklabels(), rotation=90, fontsize=10)\n",
    "    axs[1].set_ylabel('#')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d4b9020",
   "metadata": {},
   "source": [
    "## Sociological Related Categorical Features Plotted Against Death\n",
    "\n",
    "Here we are looking discern patterns from our dataset by plotting deaths (yes/no) against a number of sociological features: race, ethnicity, sex.\n",
    "\n",
    "1. The race of the patient.\n",
    "2. The ethnicity of the patient.\n",
    "3. The sex of the patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64697523",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_features = [train['race'], train['ethnicity'], train['sex']]\n",
    "select_features = [train['death_yn']]\n",
    "\n",
    "for target_feature in target_features:\n",
    "\n",
    "    for feature in select_features:\n",
    "\n",
    "        fig, axs = plt.subplots(ncols=2, figsize=(20, 8))\n",
    "        train.groupby([target_feature, feature]).size().unstack().plot(kind='bar', stacked=True, ax=axs[0])\n",
    "        axs[0].set_xticklabels(axs[0].get_xticklabels(), rotation=90, fontsize=10)\n",
    "        axs[0].set_ylabel('%')\n",
    "\n",
    "        train.groupby([target_feature, feature]).size().unstack().apply(lambda x: x/x.sum(), axis=1).plot(kind='bar', stacked=True, ax=axs[1])\n",
    "        axs[1].set_xticklabels(axs[1].get_xticklabels(), rotation=90, fontsize=10)\n",
    "        axs[1].set_ylabel('#')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d853dfd",
   "metadata": {},
   "source": [
    "## Observations/Summary:\n",
    "\n",
    "1. As the COVID19 pandemic progressed, we can generally observe both a reduction in the number of deaths per month and the proporption of deaths with regards the whole, month-on-month. The outlier here is January 2022. From the CDC dataset provided, we cannot discern whether or not the patient was vaccinated, however we can use the months here as a proxy for the Vaccine rollout program in the US, which began mid-December 2020 and had more or less concluded by the end of the following year. The death ratio falling against total cases broadly follows the vaccination rollout scheme, despite this information not formally recorded in our dataset.\n",
    "\n",
    "2. The data also suggests that age is a predominant and robust factor when gauging the impact contracting COVID will have on your health. Our data shows that those who belong to the oldest age bracket (65+) and test positive for COVID are far more likely to die than those who are younger (compare 65+ against 0-17 years old). Our data also shows that those who are older are more exposed to the risk of COVID, in that the oldest age bucket leads in terms of hospitalisations, ICU admissions, and underlying conditions in comparison to the other age brackets. This aligns with what is now known about COVID-19, that older adults and those with underlying health conditions are considered to be at a higher risk of severe illness and death from COVID-19. \n",
    "\n",
    "3. The data also demonstrates that having underlying medical conditions increases the risk of hospitalisation, ICU admission, and death from COVID-19. And while we do not get access to the comorbidities affecting the patients in our dataset, those who reported as having underlying conditions such as diabtes, hypertension, obesity (etc.), confer a much higher risk of death from COVID-19 than others.\n",
    "\n",
    "4. The data also shows that in the event of being admitted to hospital or the ICU, the success of making a full recovery is limited, and drasticly decreases the older you are. The data also proves the opposite whereby the younger you are the more resilient you are to COVID, leading to far fewer hospitalisation, admissions to ICU, and deaths. \n",
    "\n",
    "5. The data also shows that minorities, categorised in our race and ethnicity features (Black, Hispanic, Asian), are hospitalised, admitted to ICU, and die more regularly than their white counterparts pro rata. Without more granular information on our patient it is hard to say exactly what factors are driving these disparities: access to healthcare; wealth; etc.,\n",
    "\n",
    "6. The data also demonstrates that there is a weak correlation between case_onset_intervals and case_positive_specimen_intervals, with the correlation coefficient is close to zero. This indicates that the timing of when a person experiences symptoms (case onset interval) and when they test positive for COVID-19 (case positive specimen interval) are not strongly associated with each other.\n",
    "\n",
    "7. Our data also shows that there is a weak negative correlation between our continuous features, and when we map these continuous features against our target feature, there is no real discernible pattern that differents yes from no.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50b7bb47",
   "metadata": {},
   "source": [
    "## Selected Features\n",
    "\n",
    "Based on the above observations, the subset of features we are going to use to model the health profile of our patients are: \n",
    "\n",
    "i. <b>Age Group</b>, \n",
    "ii. <b>Case Month</b>, \n",
    "iii. <b>Hospilisation Status</b>, \n",
    "iv. <b>ICU Status</b>, \n",
    "v. <b>Underlying conditions</b>. \n",
    "\n",
    "Let's transform these features into new features with discrete values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a1c0547",
   "metadata": {},
   "source": [
    "#### Case Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fec46d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_map = {'2020-01': 0, \n",
    "             '2020-02': 1, \n",
    "             '2020-03': 2, \n",
    "             '2020-04': 3,\n",
    "             '2020-05': 4,\n",
    "             '2020-06': 5,\n",
    "             '2020-07': 6,\n",
    "             '2020-08': 7,\n",
    "             '2020-09': 8,\n",
    "             '2020-10': 9,\n",
    "             '2020-11': 10,\n",
    "             '2020-12': 11,\n",
    "             '2021-01': 12,\n",
    "             '2021-02': 13,\n",
    "             '2021-03': 14,\n",
    "             '2021-04': 15,\n",
    "             '2021-05': 16,\n",
    "             '2021-06': 17,\n",
    "             '2021-07': 18,\n",
    "             '2021-08': 19,\n",
    "             '2021-09': 20,\n",
    "             '2021-10': 21,\n",
    "             '2021-11': 22,\n",
    "             '2021-12': 23,\n",
    "             '2022-01': 24,\n",
    "             '2022-02': 25,\n",
    "             '2022-03': 26,\n",
    "             '2022-04': 27,\n",
    "             '2022-05': 28,\n",
    "             '2022-06': 29,\n",
    "             '2022-07': 30,\n",
    "             '2022-08': 31,\n",
    "             '2022-09': 32,\n",
    "             '2022-10': 33,\n",
    "             '2022-11': 34\n",
    "             }\n",
    "\n",
    "train['case_month'] = train['case_month'].map(month_map)\n",
    "test['case_month'] = test['case_month'].map(month_map)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa276b00",
   "metadata": {},
   "source": [
    "#### Age Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333451c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_map = {'0 - 17 years': 0, \n",
    "           '18 to 49 years': 1, \n",
    "           '50 to 64 years': 2, \n",
    "           '65+ years': 3\n",
    "           }\n",
    "\n",
    "train['age_group'] = train['age_group'].map(age_map)\n",
    "test['age_group'] = test['age_group'].map(age_map)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a092cab8",
   "metadata": {},
   "source": [
    "#### Hospitalisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5292c176",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosp_map = { 'Unknown': 0, \n",
    "            'Yes': 1, \n",
    "            }\n",
    "\n",
    "train['hosp_yn'] = train['hosp_yn'].map(hosp_map)\n",
    "test['hosp_yn'] = test['hosp_yn'].map(hosp_map)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c277322",
   "metadata": {},
   "source": [
    "#### ICU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c604d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_map = {'Unknown': 0, \n",
    "            'Yes': 1, \n",
    "            }\n",
    "\n",
    "train['icu_yn'] = train['icu_yn'].map(icu_map)\n",
    "test['icu_yn'] = test['icu_yn'].map(icu_map)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "339e296d",
   "metadata": {},
   "source": [
    "#### Underlying Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7302fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "underlying_map = {'Unknown': 0, \n",
    "                  'Yes': 1, \n",
    "                }\n",
    "\n",
    "train['underlying_conditions_yn'] = train['underlying_conditions_yn'].map(underlying_map)\n",
    "test['underlying_conditions_yn'] = test['underlying_conditions_yn'].map(underlying_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb9a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['definite_underlying'] = (train['underlying_conditions_yn'] == 1).astype(int)\n",
    "# train['uncertain_underlying'] = (train['underlying_conditions_yn'] == 0).astype(int)\n",
    "\n",
    "# test['definite_underlying'] = (test['underlying_conditions_yn'] == 1).astype(int)\n",
    "# test['uncertain_underlying'] = (test['underlying_conditions_yn'] == 0).astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6617f1e6",
   "metadata": {},
   "source": [
    "#### Death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f0451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "death_map = {'No': 0,\n",
    "             'Yes': 1,\n",
    "             }\n",
    "\n",
    "train['death_yn'] = train['death_yn'].map(death_map)\n",
    "test['death_yn'] = test['death_yn'].map(death_map)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb4498cd",
   "metadata": {},
   "source": [
    "# Task 2: Linear Regression\n",
    "\n",
    "The aim of this task is to perform some basic predictive analysis on the data prepared in task one. To this end, a linear regression model will be created using the training data yielded by the train-test split from the previous task. The features to be analyzed in this section are:\n",
    "\n",
    "i. <b>age</b>, \n",
    "ii. <b>case month</b>, \n",
    "iii. <b>hospilisation status</b>, \n",
    "iv. <b>ICU status</b>, \n",
    "v. <b>underlying conditions</b>. \n",
    "\n",
    " The model will then be evaluated based on its performance using the training data, the test data, and other linear regression models trained on the full dataset. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd2b8201",
   "metadata": {},
   "source": [
    "## 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2f9b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression_x_train = train[['case_month', 'age_group', 'hosp_yn', 'icu_yn', 'underlying_conditions_yn']]\n",
    "linear_regression_y_train = train['death_yn']\n",
    "\n",
    "linear_regression_x_test = test[['case_month', 'age_group', 'hosp_yn', 'icu_yn', 'underlying_conditions_yn']]\n",
    "linear_regression_y_test = test['death_yn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a313d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(linear_regression_x_train, linear_regression_y_train)\n",
    "linear_regression_y_pred = lr.predict(linear_regression_x_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5279e90e",
   "metadata": {},
   "source": [
    "## 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c3cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, coef in zip(linear_regression_x_train.columns, lr.coef_):\n",
    "    print(feature, ':', coef)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d857a5b",
   "metadata": {},
   "source": [
    "Underlying health conditions: this finding may be counterintuitive, as individuals with underlying health conditions are often thought to be at higher risk for adverse outcomes such as hospitalization or death from COVID-19. However, it is important to remember that the coefficient represents the association between the predictor variable and the target outcome after accounting for the effects of other predictor variables in the model.\n",
    "\n",
    "In this case, it is possible that other predictor variables, such as age or hospitalization status, may be more strongly associated with the target outcome than underlying health condition, and that the effect of underlying health condition on the target outcome is actually negative when these other factors are taken into account. Therefore, the negative coefficient for \"definite_underlying\" suggests that the presence of a definite underlying health condition alone may not be a strong predictor of the target outcome in this model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c8ee36c",
   "metadata": {},
   "source": [
    "## 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8abebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict target feature values for first 10 training examples\n",
    "linear_regression_y_train_pred_10 = lr.predict(linear_regression_x_train[:10])\n",
    "print(\"Predicted target feature values for first 10 training examples:\\n\", linear_regression_y_train_pred_10)\n",
    "print()\n",
    "# threshold predicted target feature values to get predicted classes\n",
    "linear_regression_y_train_pred_class_10 = (lr.predict(linear_regression_x_train[:10]) > 0.5).astype(int)\n",
    "print(\"Predicted class for first 10 training examples:\\n\", linear_regression_y_train_pred_class_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81575fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on full training set\n",
    "linear_regression_y_train_pred = lr.predict(linear_regression_x_train)\n",
    "\n",
    "linear_regression_y_train_pred_class = (linear_regression_y_train_pred > 0.5).astype(int)\n",
    "\n",
    "linear_regression_accuracy_train = accuracy_score(linear_regression_y_train, linear_regression_y_train_pred_class)\n",
    "linear_regression_confusion_train = confusion_matrix(linear_regression_y_train, linear_regression_y_train_pred_class)\n",
    "linear_regression_precision_train = precision_score(linear_regression_y_train, linear_regression_y_train_pred_class)\n",
    "linear_regression_recall_train = recall_score(linear_regression_y_train, linear_regression_y_train_pred_class)\n",
    "linear_regression_f1_train = f1_score(linear_regression_y_train, linear_regression_y_train_pred_class)\n",
    "linear_regression_mse = mean_squared_error(linear_regression_y_train, linear_regression_y_train_pred_class)\n",
    "linear_regression_r2 = r2_score(linear_regression_y_train, linear_regression_y_train_pred_class)\n",
    "\n",
    "print(\"\\nEvaluation metrics on the training set:\")\n",
    "print()\n",
    "print(\"Accuracy: {:.2f}\".format(linear_regression_accuracy_train))\n",
    "print(\"Confusion matrix:\\n\", linear_regression_confusion_train)\n",
    "print(\"Precision: {:.2f}\".format(linear_regression_precision_train))\n",
    "print(\"Recall: {:.2f}\".format(linear_regression_recall_train))\n",
    "print(\"F1 score: {:.2f}\".format(linear_regression_f1_train))\n",
    "print(\"MSE: {:.2f}\".format(linear_regression_mse))\n",
    "print(\"R^2: {:.2f}\".format(linear_regression_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1b3def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the training set and evaluate the model performance\n",
    "linear_regression_y_train_pred = lr.predict(linear_regression_x_train)\n",
    "linear_regression_mae_train = mean_absolute_error(linear_regression_y_train, linear_regression_y_train_pred)\n",
    "linear_regression_mse_train = mean_squared_error(linear_regression_y_train, linear_regression_y_train_pred)\n",
    "linear_regression_rmse_train = np.sqrt(linear_regression_mse_train)\n",
    "linear_regression_r2_train = r2_score(linear_regression_y_train, linear_regression_y_train_pred)\n",
    "\n",
    "print(\"Evaluation metrics on the training set:\")\n",
    "print()\n",
    "print(\"Mean Absolute Error: {:.2f}\".format(linear_regression_mae_train))\n",
    "print(\"Mean Squared Error: {:.2f}\".format(linear_regression_mse_train))\n",
    "print(\"Root Mean Squared Error: {:.2f}\".format(linear_regression_rmse_train))\n",
    "print(\"R2 score: {:.2f}\".format(linear_regression_r2_train))\n",
    "\n",
    "# make predictions on the test set and evaluate the model performance\n",
    "linear_regression_y_test_pred = lr.predict(linear_regression_x_test)\n",
    "linear_regression_mae_test = mean_absolute_error(linear_regression_y_test, linear_regression_y_test_pred)\n",
    "linear_regression_mse_test = mean_squared_error(linear_regression_y_test, linear_regression_y_test_pred)\n",
    "linear_regression_rmse_test = np.sqrt(linear_regression_mse_test)\n",
    "linear_regression_r2_test = r2_score(linear_regression_y_test, linear_regression_y_test_pred)\n",
    "\n",
    "print(\"\\nEvaluation metrics on the test set:\")\n",
    "print()\n",
    "print(\"Mean Absolute Error: {:.2f}\".format(linear_regression_mae_test))\n",
    "print(\"Mean Squared Error: {:.2f}\".format(linear_regression_mse_test))\n",
    "print(\"Root Mean Squared Error: {:.2f}\".format(linear_regression_rmse_test))\n",
    "print(\"R2 score: {:.2f}\".format(linear_regression_r2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025869ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\\n\", classification_report(linear_regression_y_train, linear_regression_y_train_pred_class))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51eee504",
   "metadata": {},
   "source": [
    "# Task 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a5acf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_x_train = train[['case_month', 'age_group', 'hosp_yn', 'icu_yn', 'underlying_conditions_yn']]\n",
    "logistic_regression_y_train = train['death_yn']\n",
    "\n",
    "logistic_regression_x_test = test[['case_month', 'age_group', 'hosp_yn', 'icu_yn', 'underlying_conditions_yn']]\n",
    "logistic_regression_y_test = test['death_yn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d49b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "logr = LogisticRegression()\n",
    "logr.fit(logistic_regression_x_train, logistic_regression_y_train)\n",
    "logistic_regression_y_pred = logr.predict(logistic_regression_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166587bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print coefficients learned by the model\n",
    "logistic_regression_coef = logr.coef_\n",
    "logistic_regression_intercept = logr.intercept_\n",
    "feature_names = logistic_regression_x_train.columns\n",
    "\n",
    "print(\"Intercept: {:.2f}\".format(logistic_regression_intercept[0]))\n",
    "print()\n",
    "for i, name in enumerate(feature_names):\n",
    "    print(\"{}: {:.2f}\".format(name, logistic_regression_coef[0][i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e07e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_y_train_pred_10 = logr.predict_proba(logistic_regression_x_train)[:, 1][:10]\n",
    "print(\"Predicted target feature values for the first 10 training examples:\\n\", logistic_regression_y_train_pred_10)\n",
    "print()\n",
    "logistic_regression_y_train_pred_class_10 = (logr.predict(logistic_regression_x_train[:10]) > 0.5).astype(int)\n",
    "print(\"Predicted class for the first 10 training examples:\\n\", logistic_regression_y_train_pred_class_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a9bb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict target feature values for full training set\n",
    "logistic_regression_y_train_pred = logr.predict_proba(logistic_regression_x_train)[:, 1]\n",
    "\n",
    "# threshold predicted target feature values at 0.5 to get predicted class for full training set\n",
    "logistic_regression_y_train_pred_class = (logistic_regression_y_train_pred >= 0.5).astype(int)\n",
    "\n",
    "logistic_regression_accuracy_train = accuracy_score(logistic_regression_y_train, logistic_regression_y_train_pred_class)\n",
    "logistic_regression_confusion_train = confusion_matrix(logistic_regression_y_train, logistic_regression_y_train_pred_class)\n",
    "logistic_regression_precision_train = precision_score(logistic_regression_y_train, logistic_regression_y_train_pred_class)\n",
    "logistic_regression_recall_train = recall_score(logistic_regression_y_train, logistic_regression_y_train_pred_class)\n",
    "logistic_regression_f1_train = f1_score(logistic_regression_y_train, logistic_regression_y_train_pred_class)\n",
    "\n",
    "print(\"\\nEvaluation metrics on the training set:\")\n",
    "print()\n",
    "print(\"Accuracy: {:.2f}\".format(logistic_regression_accuracy_train))\n",
    "print(\"Confusion matrix:\\n\", logistic_regression_confusion_train)\n",
    "print(\"Precision: {:.2f}\".format(logistic_regression_precision_train))\n",
    "print(\"Recall: {:.2f}\".format(logistic_regression_recall_train))\n",
    "print(\"F1 score: {:.2f}\".format(logistic_regression_f1_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3f8b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the training set and evaluate the model performance\n",
    "logistic_regression_y_train_pred = logr.predict(logistic_regression_x_train)\n",
    "logistic_regression_mae_train = mean_absolute_error(logistic_regression_y_train, logistic_regression_y_train_pred)\n",
    "logistic_regression_mse_train = mean_squared_error(logistic_regression_y_train, logistic_regression_y_train_pred)\n",
    "logistic_regression_rmse_train = np.sqrt(logistic_regression_mse_train)\n",
    "logistic_regression_r2_train = r2_score(logistic_regression_y_train, logistic_regression_y_train_pred)\n",
    "\n",
    "print(\"Evaluation metrics on the training set:\")\n",
    "print()\n",
    "print(\"Mean Absolute Error: {:.2f}\".format(logistic_regression_mae_train))\n",
    "print(\"Mean Squared Error: {:.2f}\".format(logistic_regression_mse_train))\n",
    "print(\"Root Mean Squared Error: {:.2f}\".format(logistic_regression_rmse_train))\n",
    "print(\"R2 score: {:.2f}\".format(logistic_regression_r2_train))\n",
    "\n",
    "# make predictions on the test set and evaluate the model performance\n",
    "logistic_regression_y_test_pred = logr.predict(logistic_regression_x_test)\n",
    "logistic_regression_mae_test = mean_absolute_error(logistic_regression_y_test, logistic_regression_y_test_pred)\n",
    "logistic_regression_mse_test = mean_squared_error(logistic_regression_y_test, logistic_regression_y_test_pred)\n",
    "logistic_regression_rmse_test = np.sqrt(logistic_regression_mse_test)\n",
    "logistic_regression_r2_test = r2_score(logistic_regression_y_test, logistic_regression_y_test_pred)\n",
    "\n",
    "print(\"\\nEvaluation metrics on the test set:\")\n",
    "print()\n",
    "print(\"Mean Absolute Error: {:.2f}\".format(logistic_regression_mae_test))\n",
    "print(\"Mean Squared Error: {:.2f}\".format(logistic_regression_mse_test))\n",
    "print(\"Root Mean Squared Error: {:.2f}\".format(logistic_regression_rmse_test))\n",
    "print(\"R2 score: {:.2f}\".format(logistic_regression_r2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f6e792",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\\n\", classification_report(logistic_regression_y_train, logistic_regression_y_train_pred_class))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8441f801",
   "metadata": {},
   "source": [
    "# Task 4: Random Forest\n",
    "### Train a random forest model to predict the target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc60450",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_x_train = train[['case_month', 'age_group', 'hosp_yn', 'icu_yn', 'underlying_conditions_yn']]\n",
    "random_forest_y_train = train['death_yn']\n",
    "\n",
    "random_forest_x_test = test[['case_month', 'age_group', 'hosp_yn', 'icu_yn', 'underlying_conditions_yn']]\n",
    "random_forest_y_test = test['death_yn']\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rfc.fit(random_forest_x_train, random_forest_y_train)\n",
    "\n",
    "random_forest_y_pred = rfc.predict(random_forest_x_test)\n",
    "\n",
    "random_forest_accuracy = accuracy_score(random_forest_y_test, random_forest_y_pred)\n",
    "print(\"Accuracy: \", random_forest_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3931368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({'feature': random_forest_x_train.columns, 'importance':rfc.feature_importances_})\n",
    "feature_importance.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a3aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_y_train_pred_10 = rfc.predict_proba(random_forest_x_train)[:, 1][:10]\n",
    "print(\"Predicted target feature values for the first 10 training examples:\\n\", random_forest_y_train_pred_10)\n",
    "print()\n",
    "random_forest_y__train_pred_class_10 = (rfc.predict(random_forest_x_train[:10]) > 0.5).astype(int)\n",
    "print(\"Predicted class for the first 10 training examples:\\n\", random_forest_y__train_pred_class_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0da5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict target feature values for full training set\n",
    "random_forest_y_train_pred = rfc.predict_proba(random_forest_x_train)[:, 1]\n",
    "\n",
    "# threshold predicted target feature values at 0.5 to get predicted class for full training set\n",
    "random_forest_y_train_pred_class = (random_forest_y_train_pred >= 0.5).astype(int)\n",
    "\n",
    "random_forest_accuracy_train = accuracy_score(random_forest_y_train, random_forest_y_train_pred_class)\n",
    "random_forest_confusion_train = confusion_matrix(random_forest_y_train, random_forest_y_train_pred_class)\n",
    "random_forest_precision_train = precision_score(random_forest_y_train, random_forest_y_train_pred_class)\n",
    "random_forest_recall_train = recall_score(random_forest_y_train, random_forest_y_train_pred_class)\n",
    "random_forest_f1_train = f1_score(random_forest_y_train, random_forest_y_train_pred_class)\n",
    "\n",
    "print(\"\\nEvaluation metrics on the training set:\")\n",
    "print()\n",
    "print(\"Accuracy: {:.2f}\".format(random_forest_accuracy_train))\n",
    "print(\"Confusion matrix:\\n\", random_forest_confusion_train)\n",
    "print(\"Precision: {:.2f}\".format(random_forest_precision_train))\n",
    "print(\"Recall: {:.2f}\".format(random_forest_recall_train))\n",
    "print(\"F1 score: {:.2f}\".format(random_forest_f1_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d71695",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\\n\", classification_report(random_forest_y_train, random_forest_y_train_pred_class))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73374cf1",
   "metadata": {},
   "source": [
    "## Random Forest Regressor - Additional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ab0354",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_reg_x_train = train[['case_month', 'age_group', 'hosp_yn', 'icu_yn', 'underlying_conditions_yn']]\n",
    "random_forest_reg_y_train = train['death_yn']\n",
    "\n",
    "random_forest_reg_x_test = test[['case_month', 'age_group', 'hosp_yn', 'icu_yn', 'underlying_conditions_yn']]\n",
    "random_forest_reg_y_test = test['death_yn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f47100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor() # create instance of the model\n",
    "rfr.fit(random_forest_reg_x_train, random_forest_reg_y_train) # fit the model to the training data\n",
    "\n",
    "random_forest_reg_y_pred = rfr.predict(random_forest_reg_x_test)\n",
    "\n",
    "#Evaluate the performance of your model:\n",
    "random_forest_reg_mse = mean_squared_error(random_forest_reg_y_test, random_forest_reg_y_pred)\n",
    "print(\"Mean Squared Error:\", random_forest_reg_mse)\n",
    "\n",
    "random_forest_reg_score = rfr.score(random_forest_reg_x_test, random_forest_reg_y_test)\n",
    "print(f\"R^2 score on testing data: {random_forest_reg_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4152af76",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_reg_y_train_pred_10 = rfr.predict(random_forest_reg_x_train)[:10]\n",
    "print(\"Predicted target feature values for the first 10 training examples:\\n\", random_forest_reg_y_train_pred_10)\n",
    "print()\n",
    "random_forest_reg_y_train_pred_class_10 = (rfr.predict(random_forest_reg_x_train[:10]) > 0.5).astype(int)\n",
    "print(\"Predicted class for the first 10 training examples:\\n\", random_forest_reg_y_train_pred_class_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac34917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict target feature values for full training set\n",
    "random_forest_reg_y_train_pred = rfr.predict(random_forest_reg_x_train)\n",
    "\n",
    "# threshold predicted target feature values at 0.5 to get predicted class for full training set\n",
    "random_forest_reg_y_train_pred_class = (random_forest_reg_y_train_pred >= 0.5).astype(int)\n",
    "\n",
    "random_forest_reg_accuracy_train = accuracy_score(random_forest_reg_y_train, random_forest_reg_y_train_pred_class)\n",
    "random_forest_reg_confusion_train = confusion_matrix(random_forest_reg_y_train, random_forest_reg_y_train_pred_class)\n",
    "random_forest_reg_precision_train = precision_score(random_forest_reg_y_train, random_forest_reg_y_train_pred_class)\n",
    "random_forest_reg_recall_train = recall_score(random_forest_reg_y_train, random_forest_reg_y_train_pred_class)\n",
    "random_forest_reg_f1_train = f1_score(random_forest_reg_y_train, random_forest_reg_y_train_pred_class)\n",
    "\n",
    "print(\"\\nEvaluation metrics on the training set:\")\n",
    "print()\n",
    "print(\"Accuracy: {:.2f}\".format(random_forest_reg_accuracy_train))\n",
    "print(\"Confusion matrix:\\n\", random_forest_reg_confusion_train)\n",
    "print(\"Precision: {:.2f}\".format(random_forest_reg_precision_train))\n",
    "print(\"Recall: {:.2f}\".format(random_forest_reg_recall_train))\n",
    "print(\"F1 score: {:.2f}\".format(random_forest_reg_f1_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c565158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\\n\", classification_report(random_forest_reg_y_train, random_forest_reg_y_train_pred_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
